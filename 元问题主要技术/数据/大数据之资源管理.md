# 大数据之资源管理
## yarn(对标mesos和docker)
* 独立部署一个resource manager节点集群，代码提交给它，它通过与nodemanager通讯，将某个MapReduce作业对应的application master程序分派到一个datanode的一个容器中执行，application master向resource manager汇报每个datanode的资源使用情况，resource manager通过fair或capacity算法分配map或reduce任务给不同datanode。resource manager；
* 每个datanode进程节点上部署一个nodemanager进程，将节点分成一个个容器，每个容器都拥有自己的cpu和内存等资源。
## mesos

> 注1：ApplicationMaster 向资源管理器申请计算资源时可以指定目标节点（数据分片所在节点），而如果系统资源能够满足，就会把mapreduce计算任务分发到指定的服务器上。如果资源不允许，比如目标节点非常繁忙，这时部分mapreduce计算任务可能会分配另外的服务器（数据分片不在本地，即做不到边缘计算，数据需要传到map和reduce程序所在节点）

> 注2：为何专门起一个application master来给resource manager汇报和为mr作业申请资源，而非利用node manager(这样一个datanode很可能就有datanode、nodemanager、application master三个进程了)?这是因为一是节点管理(nodemanager)和作业监控/资源申请(application master)进行解耦，可以兼容各种计算框架(MapReduce、spark等)，计算框架只要遵循yarn规范写applicationmaster即可实现自己的资源调度策略，二是每个MapReduce作业都对应一个application master，即每个作业可以定制化自己的资源调度策略，也有默认策略(fair或capacity)。可以说，application master是面向某个map和reduce应用的，而node manager是面向某个datanode的