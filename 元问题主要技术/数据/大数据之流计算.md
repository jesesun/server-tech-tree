# 大数据之流计算
## Storm
* nimbus 是集群的 Master，负责集群管理、任务分配等。supervisor 是 Slave，是真正完成计算的地方，每个 supervisor 启动多个 worker 进程，每个 worker 上运行多个 task，而 task 就是 spout 或者 bolt。storm将spout和bolt组成一个topology进行任务分发和关联。supervisor 和 nimbus 通过 ZooKeeper 完成任务分配、心跳检测等操作。
* Hadoop、Storm 的设计理念，其实是一样的，就是把和具体业务逻辑无关的东西抽离出来，形成一个框架，比如大数据的分片处理、数据的流转、任务的部署与执行等，开发者只需要按照框架的约束，开发业务逻辑代码(spout和bolt)，提交给框架执行就可以了。