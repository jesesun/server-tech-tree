# 分布式调度中心
还包括了性能
* 代表：quartz、xxl-job
* 关键技术：数据分片、分布式处理、任务编排、监控管理

# 配置中心
* 代表：Archaius、Spring Cloud Config
* 关键技术

# 服务治理
  * 服务监视：依赖链路、错误率、时延、容量、APM、故障定位
  * 服务控制：上下架服务、故障处理、服务路由、限流降级、授权、灰度发布（也称金丝雀发布，先将新版发布到少量节点，验证ok再全量发布全节点）、蓝绿发布（先把蓝流量断掉，只绿接流量，蓝发新版，测试验证OK切流量到蓝，绿断掉流量并发版，绿验证OK后重接流量，至此蓝绿都以新版本接流量）、AB test（发布不同版本到不同集群，以分析不同版本的效果）

# log(可能要划分到数据)
ELK。log的设计思路和目标？？

# 监控
美团点评CAT、zabbix。监控的设计思路和目标？？

# 识别基础架构模块
# 防止架构腐化
# 系统热部署
# 《智能运维》从0搭建大规模分布式AIOps系统

# 资源调度框架
yarn(对标mesos和docker)
* 独立部署一个resource manager节点集群，代码提交给它，它通过与nodemanager通讯，将某个MapReduce作业对应的application master程序分派到一个datanode的一个容器中执行，application master向resource manager汇报每个datanode的资源使用情况，resource manager通过fair或capacity算法分配map或reduce任务给不同datanode。resource manager；
* 每个datanode进程节点上部署一个nodemanager进程，将节点分成一个个容器，每个容器都拥有自己的cpu和内存等资源。

> 注1：ApplicationMaster 向资源管理器申请计算资源时可以指定目标节点（数据分片所在节点），而如果系统资源能够满足，就会把mapreduce计算任务分发到指定的服务器上。如果资源不允许，比如目标节点非常繁忙，这时部分mapreduce计算任务可能会分配另外的服务器（数据分片不在本地，即做不到边缘计算，数据需要传到map和reduce程序所在节点）

> 注2：为何专门起一个application master来给resource manager汇报和为mr作业申请资源，而非利用node manager(这样一个datanode很可能就有datanode、nodemanager、application master三个进程了)?这是因为一是节点管理(nodemanager)和作业监控/资源申请(application master)进行解耦，可以兼容各种计算框架(MapReduce、spark等)，计算框架只要遵循yarn规范写applicationmaster即可实现自己的资源调度策略，二是每个MapReduce作业都对应一个application master，即每个作业可以定制化自己的资源调度策略，也有默认策略(fair或capacity)。可以说，application master是面向某个map和reduce应用的，而node manager是面向某个datanode的

